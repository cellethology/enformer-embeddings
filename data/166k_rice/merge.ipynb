{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings/0_row0_row30322_gpu0_batch_8.safetensors\n",
      "Processing key: embeddings\n",
      "Processing key: expressions\n",
      "Processing key: log_likelihoods\n",
      "Processing key: variant_ids\n",
      "/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings/1_row30323_row60645_gpu0_batch_8.safetensors\n",
      "Processing key: embeddings\n",
      "Processing key: expressions\n",
      "Processing key: log_likelihoods\n",
      "Processing key: variant_ids\n",
      "/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings/2_row60646_row90968_gpu0_batch_8.safetensors\n",
      "Processing key: embeddings\n",
      "Processing key: expressions\n",
      "Processing key: log_likelihoods\n",
      "Processing key: variant_ids\n",
      "/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings/3_row90969_row121291_gpu0_batch_8.safetensors\n",
      "Processing key: embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing key: expressions\n",
      "Processing key: log_likelihoods\n",
      "Processing key: variant_ids\n"
     ]
    }
   ],
   "source": [
    "from safetensors.torch import load_file, save_file\n",
    "from glob import glob\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "all_tensor_data = {}\n",
    "base_path = \"/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings\"\n",
    "\n",
    "\n",
    "for file in sorted(glob(f\"{base_path}/*_row*.safetensors\")):\n",
    "    print(file)\n",
    "    tensor_data = load_file(file)\n",
    "\n",
    "    for key, value in tensor_data.items():\n",
    "        if key != \"sequences\":  # Skip sequences entirely\n",
    "            print(f\"Processing key: {key}\")\n",
    "            if key not in all_tensor_data:\n",
    "                all_tensor_data[key] = value\n",
    "            else:\n",
    "                all_tensor_data[key] = torch.cat([all_tensor_data[key], value], dim=0)\n",
    "        elif key == \"sequences\":\n",
    "            if key not in all_tensor_data:\n",
    "                all_tensor_data[key] = value\n",
    "            else:\n",
    "                # Find the maximum length between existing and new sequences\n",
    "                max_len = max(all_tensor_data[key].shape[1], value.shape[1])\n",
    "\n",
    "                # Pad both tensors to max length\n",
    "                existing_padded = F.pad(all_tensor_data[key], (0, max_len - all_tensor_data[key].shape[1]))\n",
    "                new_padded = F.pad(value, (0, max_len - value.shape[1]))\n",
    "\n",
    "                # Concatenate the padded tensors\n",
    "                all_tensor_data[key] = torch.cat([existing_padded, new_padded], dim=0)\n",
    "# part_tensor_data = {}\n",
    "# for key, value in all_tensor_data.items():\n",
    "#     part_tensor_data[key] = value[:1000]\n",
    "\n",
    "save_file(all_tensor_data, f\"all_tensor_data_with_sequences.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings/0_row0_row30322_gpu0_results_batch_8.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings/1_row30323_row60645_gpu0_results_batch_8.csv\n",
      "/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings/2_row60646_row90968_gpu0_results_batch_8.csv\n",
      "/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings/3_row90969_row121291_gpu0_results_batch_8.csv\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "all_df = None\n",
    "base_path = \"/home/ubuntu/zelun-enformer/enformer-embeddings/data/166k_rice/post_embeddings\"\n",
    "for file in sorted(glob(f\"{base_path}/*_8.csv\")):\n",
    "    print(file)\n",
    "    df = pd.read_csv(file, sep=',')\n",
    "    if all_df is None:\n",
    "        all_df = df\n",
    "    else:\n",
    "        all_df = pd.concat([all_df, df], ignore_index=True)\n",
    "\n",
    "all_df.to_csv(f\"{base_path}/all_data_with_sequence.csv\", sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
